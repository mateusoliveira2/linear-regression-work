---
title: ""
author: "Fanny Batista Vieira, Marcus Vin√≠cius de Farias Barbosa e Mateus de Lima Oliveira"
date: "13 de maio de 2019"
output:
  html_document:
    code_folding: "hide"
    toc: yes
    toc_depth: 5
    toc_float:
      collapsed: no
    df_print: paged
---

## Pergunta a ser respondida: Quais departamentos quando investidos interferem no lucro das startups ?

```{r}
library(tidyverse)
library(ggbeeswarm)
knitr::opts_chunk$set(tidy = FALSE, fig.width = 8, fig.height = 6, echo = TRUE)

options(scipen = 999)

dataset = read_csv(here::here("data/50_startups.csv"),
                 col_types = "dddcd")
```

## Analise Descritiva

O investimento em determinados setores pode resultar em um resultado positivo no lucro de empresas. Para verificar isso, iremos analisar dados de 50 startups de tr·s estados americanos: Florida, California e Nova Iorque. 

Vamos verificar se gastos com AdministraÁ„o, P&D(Pesquisa e Desenvolvimento) e Marketing tem alguma relaÁ„o com o lucro da startup analisando suas correlaÁıes.
Para melhorar o entendimento e analise individual, os gr·ficos  est„o divididos por estado.

### AdministraÁ„o

Com base nas visualizaÁıess abaixo, podemos notar que h· uma dispers„o dos pontos de forma que n„o se pode afirmar que h· uma correlaÁ„o consideravel em relaÁ„o ao impacto de gastos com administraÁ„o no lucro da startup. Nos tr·s estados, existem pontos que est„o no mesmo nivel de lucro mesmo conforme o investimento em administraÁ„o cresce.

**CorrelaÁ„o**
```{r}
cor(dataset$Administration, dataset$Profit)
```

```{r}
library(ggplot2)
ggplot(data = dataset) +
    theme(legend.position="none")+
    geom_point(aes(x = Administration, y = Profit, color = State)) +
    facet_grid(State ~ .) +
    labs(x = "AdministraÁ„o", y = "Lucro", title = "AdministraÁ„o X Lucro", subtitle =  "Analise de relaÁ„o entre gasto com adminsitraÁ„o e lucro")
```



### Marketing

No marketing a situaÁ„o difere da administraÁ„o. As startups tendem a ter um maior lucro de acordo com o investimento nesse setor nos tr·s estados, pois ao passo que o valor investido cresce, os lucros tambÈm crescem.
Observa-se pontos que fogem dos da tÍndencia, logo, h· uma correlaÁ„o consideravel entre essas duas vari·veis.


**CorrelaÁ„o:**
```{r}
cor(dataset$Marketing, dataset$Profit)
```

```{r}
ggplot(data = dataset) +
    theme(legend.position="none")+
    geom_point(aes(x = Marketing, y = Profit, color = State))+
    facet_grid(State ~ .) +
    labs(x = "Marketing", y = "Lucro", title = "Marketing X Lucro", subtitle =  "Analise de relaÁ„o entre gasto com marketing e lucro")
```




### Pesquisa e Desenvolvimento

Como esperado, h· uma correlaÁ„o quase linear em relaÁ„o ao lucro e investimento em pesquisa e desenvolvimento. N„o h· pontos consider·veis que saiam da tÍndencia de crescimento linar que os pontos do gr·fico seguem. 
Com isso, esse È o setor que gera um efeito positivo mais prov·vel no lucro das startups quando comparado com Marketing e AdministraÁ„o.

**CorrelaÁ„o:**
```{r}
cor(dataset$ReD, dataset$Profit)
```

```{r}
ggplot(data = dataset) +
    theme(legend.position="none")+
    geom_point(aes(x = ReD, y = Profit, color = State)) +
    facet_grid(State ~ .) +
    labs(x = "P&D", y = "Lucro", title = "P&D X Lucro", subtitle =  "Analise de relaÁ„o entre gasto com pesquisa & desenvolvimento e lucro")
```

```{r}
ggplot(data = dataset) +
    theme(legend.position="none")+
    geom_point(aes(x = ReD, y = Profit, color = State)) +
    labs(x = "P&D", y = "Lucro", title = "P&D X Lucro", subtitle =  "Analise de relaÁ„o entre gasto com pesquisa & desenvolvimento e lucro")
```



### ComparaÁ„o de estados

```{r}
ggplot(data = dataset) +
    geom_quasirandom(aes(x = State, y = Profit, color = State, alpha = 0.3))+
    geom_boxplot(aes(x = State, y = Profit, color = State, alpha = 0.3))+
    labs(x = "", y = "Lucro", title = "Lucros por estados")

```



## Modelo de Regress√£o

### Preprocessamento dos dados

Antes de analisar os modelos que se adequam √† problem√°tica proposta, √© necess√°rio adaptar as vari√°veis que n√£o s√£o do tipo n√∫merico, pois sem isto, elas n√£o podem ser consideradas como par√¢metros dos modelos de uma regress√£o linear.

A vari√°vel adaptada √© a Estado, que pode possuir tr√™s valores categ√≥ricos: New York, California e Florida. Desse modo, ela foi transformada para receber respectivamente os valores 1, 2 e 3, possibilitando sua inclus√£o nos modelos constru√≠dos.

```{r}
dataset$State = factor(dataset$State,
                       levels = c('New York', 'California', 'Florida'),
                       labels = c(1, 2, 3))
```

√â necess√°rio tamb√©m dividir o conjunto de dados, em dois conjuntos: de treinamento e de teste. O conjunto de dados de treinamento √© utilizado para construir e treinar o modelo, j√° o de testes √© utilizado para verificar o qu√£o acertivo est√° o modelo.
Forma utilizados 80% dos dados para o conjunto de treinamento e 20% para o conjunto de teste.

```{r}
library(caTools)
set.seed(100)
split = sample.split(dataset$Profit, SplitRatio = 0.8)

training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
```

### Encontrando o melhor modelo

A fim de encontrar o melhor modelo √© utilizada a t√©cnica Backward Elimination. Atrav√©s da qual √© criado um primeiro modelo considerando todas as vari√°veis independentes, e a partir disso v√£o sendo exclu√≠das, uma por uma, as vari√°veis que n√£o s√£o relevantes para predi√ß√£o.

```{r}
regressor = lm(formula = Profit ~ .,
               data = training_set)
summary(regressor)
```
```{r}
regressor = lm(formula = Profit ~ Marketing + ReD + State,
               data = training_set)
summary(regressor)
```
```{r}
regressor = lm(formula = Profit ~ Marketing + ReD,
               data = training_set)
summary(regressor)
```
Modelo em que todos os estimadores dos par√¢metros foram significativos.

```{r}
regressor = lm(formula = Profit ~ ReD,
               data = training_set)
summary(regressor)
```

## An√°lise de Res√≠duos

Os res√≠duos representam as diferen√ßas entre os valores do fen√¥meno que estamos observando, no nosso caso, s√£o os valores que observamos no dataset. E os valores estimados, a partir do nosso modelo. De modo formal, um res√≠duo pode ser obtido pela seguinte f√≥rmula:

```
    ei = yi - yi'
```

onde:  
ei -> indica o i√©simo erro  
yi -> indica o i√©simo valor observado  
yi'-> indica o i√©simo valor estimado  

A an√°lise dos res√≠duos, consiste em validar se o modelo adotado, de fato, √© adequado para o contexto do problema, baseado nas suposi√ß√µes feitas para os dados, s√£o elas: 

 - **Linearidade**: Esperamos que os dados tenham uma rela√ß√£o linear.  
 - **Normalidade**: Os res√≠duos devem seguir a distribui√ß√£o normal, com m√©dia igual a 0 e vari√¢ncia constante.  
 - **Homogeneidade**: Os res√≠duos devem variar na mesma propor√ß√£o. Desta forma, cada um contribui de forma igual para a soma dos quadrados.  
 - **Independ√™ncia**: Um res√≠duo n√£o deve influenciar o outro, essa suposi√ß√£o, garante que os dados foram coletados de modo aleat√≥rio no espa√ßo amostral.


No gr√°fico abaixo, vemos os valores observados, representados pelos c√≠rculos ao longo da reta, os valores estimados, indicados pelos c√≠rculos coloridos maiores, e os res√≠duos, que s√£o as linhas entre os valores estimados e os observados.

A partir dele, conseguimos visualizar a exist√™ncia da rela√ß√£o linear entre as vari√°veis, e como o modelo consegue explicar boa parte dos dados, conforme visto utilizando a estat√≠stica `R¬≤`, que teve valor igual a 94%, demonstrando assim, que conseguimos explicar 94% dos dados.


```{r}
predicoes = predict(regressor)
residuos = residuals(regressor)

ggplot(training_set, aes(x = ReD, y = Profit)) +
  geom_smooth(method = "lm", se = FALSE, color = "lightgrey") +     # regression line  
  geom_segment(aes(xend = ReD, yend = predicoes), alpha = .2) +     # draw line from point to line
  geom_point(aes(color = abs(residuos), size = abs(residuos))) +    # size of the points
  scale_color_continuous(low = "green", high = "red") +             # colour of the points mapped to residual size - green smaller, red larger
  guides(color = FALSE, size = FALSE) +                             # size legend removed
  geom_point(aes(y = predicoes), shape = 1) +
  theme_bw() 
```

### Teste da linearidade

O gr√°fico abaixo, mostra se os res√≠duos possuem padr√µes de rela√ß√£o n√£o lineares.
Vemos que nossos res√≠duos n√£o possuem padr√µes estranhos, embora possua certa curvatura, os res√≠duos se distribuem ao longo da reta horizontal. O que nos d√° um bom indicador que nossos dados possuem rela√ß√£o linear.


```{r}
plot(regressor, which=1, col=c("blue"))
```


### Teste de normalidade

O grafico do tipo `qxq`, √© um tipo de gr√°fico de dispers√£o em que dado dois conjuntos de dados, √© obtido os seus quantis ordenados, colocando os valores do primeiro contra os do segundo, assim, se os dois conjuntos de quantis forem da mesma distribui√ß√£o, veremos os pontos formando uma linha que √© praticamente reta.

Dessa forma, ele auxilia a verificar se um conjunto de dados veio de alguma distribui√ß√£o te√≥rica, no nosso contexto, queremos verificar se os res√≠duos seguem distribui√ß√£o normal, sendo assim, faremos uso dela.


```{r}
plot(regressor, which=2, col=c("blue"))
```

Do gr√°fico acima, conseguimos concluir que nosso modelo segue a distribui√ß√£o normal, tendo em vista, que os res√≠duos est√£o seguindo um bom alinhamento com a reta que o nosso modelo prop√µe.


```{r}
plot(density(residuos))
```

```{r}
shapiro.test(residuos)
```

Al√©m da visualiza√ß√£o do gr√°fico qxq, tamb√©m decidimos usar o gr√°fico de densidade e o teste shapiro. No gr√°fico da densidade, vemos que o formato, √© bem similar ao da distribui√ß√£o normal, s√≥ n√£o se comporta bem para valores baixos.

Por fim, analisamos o teste de shapiro-wilk. Para verificar se a nossa hip√≥tese de que os res√≠duos seguem distribui√ß√£o normal, analisamos o valor p. Se ele for menor que o nosso n√≠vel de signific√¢ncia(nesse caso, 0.05), reijeitamos a hipotese.

A partir do resultado acima, vemos que o valor p √© menor que o n√≠vel de signific√¢ncia e portanto dever√≠amos rejeit√°-lo. Mas algo soa estranho, pelas analises visuais nossos res√≠duos parecem seguir uma distribui√ß√£o normal, ap√≥s algumas pesquisas, percebemos que o problema √© porque temos dois valores muito abaixo das outras m√©dias(nesse caso, 0), que ocorreram quando as empresas n√£o investiram em pesquisa e desenvolvimento. 

Pelo estudado, quando os valores s√£o muito pequenos, o coeficiente n√£o consegue identificar bem a presen√ßa de normalidade e por isso, obtivemos esse resultado. Sendo assim, podemos afirmar que de modo geral, nossos res√≠duos seguem distribui√ß√£o normal.


### Teste da homogeinidade

Para verificar a homogeinidade, dos res√≠duos, primeiro, utilizamos o gr√°fico do tipo cale-location. Verificamos isso de duas formas:

1. A linha vermelha √© aproximadamente horizontal. Ent√£o a magnitude m√©dia dos res√≠duos padronizados n√£o est√° mudando muito em fun√ß√£o dos valores ajustados.  
2. A propaga√ß√£o ao redor da linha vermelha n√£o varia com os valores ajustados. Ent√£o a variabilidade de magnitude n√£o varia muito em fun√ß√£o dos valores ajustados.

Apesar de existir certa curvatura, no nosso gr√°fico, de modo geral, ele se assemelha bastante ao formato linear. Al√©m disso, a segunda condi√ß√£o tamb√©m consegue ser satisfeita, pois n√£o vemos uma forte concentra√ß√£o dos dados, em nenhum dos lados(inferior e superior). Logo, somos levados a acreditar que nossos res√≠duos possuem homogeinidade.


```{r}
plot(regressor, which=3, col=c("blue"))  # Scale-Location Plot
```


Usamos o teste de Breusch Pagan, para medir numericamente se nossa suposi√ß√£o est√° correta. Ele funciona como a estat√≠stica de teste usada anteriormente, analisando o p-valor, se ele for abaixo do nosso n√≠vel de signific√¢ncia, podemos rejeitar a nossa hip√≥tese. Mas da tabela abaixo, vemos que o p-valor √© maior, e portanto podemos concluir que os res√≠duos s√£o homog√™neos.

```{r}
library(lmtest)
bptest(regressor)
```

### Teste da independ√™ncia


```{r}
library(car)
durbinWatsonTest(regressor)
```

