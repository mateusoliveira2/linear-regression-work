---
title: ""
author: "Fanny Batista Vieira, Marcus Vinícius de Farias Barbosa e Mateus de Lima Oliveira"
date: "13 de maio de 2019"
output:
  html_document:
    code_folding: "hide"
    toc: yes
    toc_depth: 5
    toc_float:
      collapsed: no
    df_print: paged
---

## Pergunta a ser respondida: Quais departamentos quando investidos interferem no lucro das startups ?

```{r}
library(tidyverse)
options(scipen = 999)

dataset = read_csv(here::here("data/50_startups.csv"),
                 col_types = "dddcd")
```

## Análise Descritiva

### Visualização dos dados
OBS: Inserir Heatmap

```{r}
library(ggplot2)
ggplot(data = dataset) +
  geom_point(aes(x = Administration, y = Profit, color = State)) +
  facet_grid(State ~ .) +
  ggtitle('Administration Spend X Profit')

ggplot(data = dataset) +
  geom_point(aes(x = Marketing, y = Profit, color = State)) +
  facet_grid(State ~ .) +
  ggtitle('Marketing Spend X Profit')

ggplot(data = dataset) +
  geom_point(aes(x = ReD, y = Profit, color = State)) +
  facet_grid(State ~ .) +
  ggtitle('ReD Spend X Profit')

ggplot(data = dataset) +
  geom_bar(aes(State, fill = State)) +
  ggtitle('Administration X Profit')

ggplot(data = dataset) +
  geom_point(aes(x = State, y = Profit, color = State))

```

### Análise da Correlação

```{r}
cor(dataset$Administration, dataset$Profit)
cor(dataset$Marketing, dataset$Profit)
cor(dataset$ReD, dataset$Profit)
```

## Modelo de Regressão

### Preprocessamento dos dados

Antes de analisar os modelos que se adequam à problemática proposta, é necessário adaptar as variáveis que não são do tipo númerico, pois sem isto, elas não podem ser consideradas como parâmetros dos modelos de uma regressão linear.

A variável adaptada é a Estado, que pode possuir três valores categóricos: New York, California e Florida. Desse modo, ela foi transformada para receber respectivamente os valores 1, 2 e 3, possibilitando sua inclusão nos modelos construídos.

```{r}
dataset$State = factor(dataset$State,
                       levels = c('New York', 'California', 'Florida'),
                       labels = c(1, 2, 3))
```

É necessário também dividir o conjunto de dados, em dois conjuntos: de treinamento e de teste. O conjunto de dados de treinamento é utilizado para construir e treinar o modelo, já o de testes é utilizado para verificar o quão acertivo está o modelo.
Forma utilizados 80% dos dados para o conjunto de treinamento e 20% para o conjunto de teste.

```{r}
library(caTools)
set.seed(100)
split = sample.split(dataset$Profit, SplitRatio = 0.8)

training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
```

### Encontrando o melhor modelo

A fim de encontrar o melhor modelo é utilizada a técnica Backward Elimination. Através da qual é criado um primeiro modelo considerando todas as variáveis independentes, e a partir disso vão sendo excluídas, uma por uma, as variáveis que não são relevantes para predição.

```{r}
regressor = lm(formula = Profit ~ .,
               data = training_set)
summary(regressor)
```
```{r}
regressor = lm(formula = Profit ~ Marketing + ReD + State,
               data = training_set)
summary(regressor)
```
```{r}
regressor = lm(formula = Profit ~ Marketing + ReD,
               data = training_set)
summary(regressor)
```
Modelo em que todos os estimadores dos parâmetros foram significativos.

```{r}
regressor = lm(formula = Profit ~ ReD,
               data = training_set)
summary(regressor)
```

## Análise de Resíduos

Os resíduos representam as diferenças entre os valores do fenômeno que estamos observando, no nosso caso, são os valores que observamos no dataset. E os valores estimados, a partir do nosso modelo. De modo formal, um resíduo pode ser obtido pela seguinte fórmula:

```
    ei = yi - yi'
```

onde:  
ei -> indica o iésimo erro  
yi -> indica o iésimo valor observado  
yi'-> indica o iésimo valor estimado  

A análise dos resíduos, consiste em validar se o modelo adotado, de fato, é adequado para o contexto do problema, baseado nas suposições feitas para os dados, são elas: 

 - **Linearidade**: Esperamos que os dados tenham uma relação linear.  
 - **Normalidade**: Os resíduos devem seguir a distribuição normal, com média igual a 0 e variância constante.  
 - **Homogeneidade**: Os resíduos devem variar na mesma proporção. Desta forma, cada um contribui de forma igual para a soma dos quadrados.  
 - **Independência**: Um resíduo não deve influenciar o outro, essa suposição, garante que os dados foram coletados de modo aleatório no espaço amostral.


No gráfico abaixo, vemos os valores observados, representados pelos círculos ao longo da reta, os valores estimados, indicados pelos círculos coloridos maiores, e os resíduos, que são as linhas entre os valores estimados e os observados.

A partir dele, conseguimos visualizar a existência da relação linear entre as variáveis, e como o modelo consegue explicar boa parte dos dados, conforme visto utilizando a estatística `R²`, que teve valor igual a 94%, demonstrando assim, que conseguimos explicar 94% dos dados.


```{r}
predicoes = predict(regressor)
residuos = residuals(regressor)

ggplot(training_set, aes(x = ReD, y = Profit)) +
  geom_smooth(method = "lm", se = FALSE, color = "lightgrey") +     # regression line  
  geom_segment(aes(xend = ReD, yend = predicoes), alpha = .2) +     # draw line from point to line
  geom_point(aes(color = abs(residuos), size = abs(residuos))) +    # size of the points
  scale_color_continuous(low = "green", high = "red") +             # colour of the points mapped to residual size - green smaller, red larger
  guides(color = FALSE, size = FALSE) +                             # size legend removed
  geom_point(aes(y = predicoes), shape = 1) +
  theme_bw() 
```

### Teste da linearidade

O gráfico abaixo, mostra se os resíduos possuem padrões de relação não lineares.
Vemos que nossos resíduos não possuem padrões estranhos, embora possua certa curvatura, os resíduos se distribuem ao longo da reta horizontal. O que nos dá um bom indicador que nossos dados possuem relação linear.


```{r}
plot(regressor, which=1, col=c("blue"))
```


### Teste de normalidade

O grafico do tipo `qxq`, é um tipo de gráfico de dispersão em que dado dois conjuntos de dados, é obtido os seus quantis ordenados, colocando os valores do primeiro contra os do segundo, assim, se os dois conjuntos de quantis forem da mesma distribuição, veremos os pontos formando uma linha que é praticamente reta.

Dessa forma, ele auxilia a verificar se um conjunto de dados veio de alguma distribuição teórica, no nosso contexto, queremos verificar se os resíduos seguem distribuição normal, sendo assim, faremos uso dela.


```{r}
plot(regressor, which=2, col=c("blue"))
```

Do gráfico acima, conseguimos concluir que nosso modelo segue a distribuição normal, tendo em vista, que os resíduos estão seguindo um bom alinhamento com a reta que o nosso modelo propõe.


```{r}
plot(density(residuos))
```

```{r}
shapiro.test(residuos)
```

Além da visualização do gráfico qxq, também decidimos usar o gráfico de densidade e o teste shapiro. No gráfico da densidade, vemos que o formato, é bem similar ao da distribuição normal, só não se comporta bem para valores baixos.

Por fim, analisamos o teste de shapiro-wilk. Para verificar se a nossa hipótese de que os resíduos seguem distribuição normal, analisamos o valor p. Se ele for menor que o nosso nível de significância(nesse caso, 0.05), reijeitamos a hipotese.

A partir do resultado acima, vemos que o valor p é menor que o nível de significância e portanto deveríamos rejeitá-lo. Mas algo soa estranho, pelas analises visuais nossos resíduos parecem seguir uma distribuição normal, após algumas pesquisas, percebemos que o problema é porque temos dois valores muito abaixo das outras médias(nesse caso, 0), que ocorreram quando as empresas não investiram em pesquisa e desenvolvimento. 

Pelo estudado, quando os valores são muito pequenos, o coeficiente não consegue identificar bem a presença de normalidade e por isso, obtivemos esse resultado. Sendo assim, podemos afirmar que de modo geral, nossos resíduos seguem distribuição normal.


### Teste da homogeinidade

Para verificar a homogeinidade, dos resíduos, primeiro, utilizamos o gráfico do tipo cale-location. Verificamos isso de duas formas:

1. A linha vermelha é aproximadamente horizontal. Então a magnitude média dos resíduos padronizados não está mudando muito em função dos valores ajustados.  
2. A propagação ao redor da linha vermelha não varia com os valores ajustados. Então a variabilidade de magnitude não varia muito em função dos valores ajustados.

Apesar de existir certa curvatura, no nosso gráfico, de modo geral, ele se assemelha bastante ao formato linear. Além disso, a segunda condição também consegue ser satisfeita, pois não vemos uma forte concentração dos dados, em nenhum dos lados(inferior e superior). Logo, somos levados a acreditar que nossos resíduos possuem homogeinidade.


```{r}
plot(regressor, which=3, col=c("blue"))  # Scale-Location Plot
```


Usamos o teste de Breusch Pagan, para medir numericamente se nossa suposição está correta. Ele funciona como a estatística de teste usada anteriormente, analisando o p-valor, se ele for abaixo do nosso nível de significância, podemos rejeitar a nossa hipótese. Mas da tabela abaixo, vemos que o p-valor é maior, e portanto podemos concluir que os resíduos são homogêneos.

```{r}
library(lmtest)
bptest(regressor)
```

### Teste da independência


```{r}
library(car)
durbinWatsonTest(regressor)
```

