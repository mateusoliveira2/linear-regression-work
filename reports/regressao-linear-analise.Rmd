---
title: "Quais gastos interferem no lucro de uma startup ?"
author: "Fanny Batista Vieira, Marcus Vinícius de Farias Barbosa e Mateus de Lima Oliveira"
date: "10 de junho de 2019"
output:
  html_document:
    code_folding: "hide"
    toc: yes
    toc_depth: 5
    toc_float:
      collapsed: no
    df_print: paged
---

```{r results='hide', message=FALSE, warning=FALSE}
library(tidyverse)
library(ggbeeswarm)
library(ggplot2)
library(corrplot)
library(caTools)
library(lmtest)
library(car)

knitr::opts_chunk$set(tidy = FALSE, fig.width = 8, fig.height = 6, echo = TRUE)

options(scipen = 999)

dataset = read_csv(here::here("data/50_startups.csv"),
                 col_types = "dddcd")

names(dataset)[names(dataset) == 'ReD'] <- 'PeD'
names(dataset)[names(dataset) == 'Administration'] <- 'Administracao'
names(dataset)[names(dataset) == 'State'] <- 'Estado'
names(dataset)[names(dataset) == 'Profit'] <- 'Lucro'
```

## Motivação

Os dados utilizados possuem informações sobre 50 startups. Temos cinco colunas que contêm informações sobre quanto essas empresas gastam em administração, pesquisa e desenvolvimento (P&D) e marketing, sua localização por estado e seu lucro no ano mais recente. Este conjunto de dados é anonimizado, o que significa que não sabemos os nomes dessas startups ou qualquer outra informação de identificação.

Pensamos no cenário em que seríamos contratados para analisar essas informações e criar um modelo. Precisaríamos responder ao contratante em quais departamentos da empresa devem-se investir para se obter um maior lucro, por exemplo em administração, ou em outro setor. O nosso empregador informou que deseja tomar essa decisão com base no lucro do ano passado.

Para resolver esse problema, criaremos um modelo para avaliar quais departamentos de uma startup são interessantes para se investir, a fim maximizar seu lucro.

## Análise Descritiva

### Administração

Com base nas visualizações abaixo, podemos notar que há uma dispersão dos pontos, de modo que não se pode afirmar que há uma correlação considerável entre os gastos com administração e o lucro da startup. Nos três estados, existem pontos que estão no mesmo nível de lucro mesmo com o crescimento dos gastos em administração.

```{r}
ggplot(data = dataset) +
    theme(legend.position="none")+
    geom_point(aes(x = Administracao, y = Lucro, color = Estado)) +
    facet_grid(Estado ~ .) +
    labs(x = "Administração", y = "Lucro", title = "Administração X Lucro", subtitle =  "Analise de relação entre gasto com administração e o lucro")
```

### Marketing

No marketing, a situação difere da administração. As startups tendem a ter um maior lucro de acordo com o investimento nesse setor nos três estados, pois ao passo que o valor investido cresce, os lucros também crescem.
Observa-se pontos que fogem da têndencia, logo, há uma correlação considerável entre essas duas variáveis.

```{r}
ggplot(data = dataset) +
    theme(legend.position="none")+
    geom_point(aes(x = Marketing, y = Lucro, color = Estado))+
    facet_grid(Estado ~ .) +
    labs(x = "Marketing", y = "Lucro", title = "Marketing X Lucro", subtitle =  "Analise de relação entre gasto com marketing e lucro")
```

### Pesquisa e Desenvolvimento

Como esperado, há uma correlação quase linear em relação ao lucro e o investimento em pesquisa e desenvolvimento. Não há pontos consideráveis que saiam da têndencia de crescimento linear que os pontos do gráfico seguem. 
Com isso, esse é o setor que gera um efeito positivo mais provável no lucro das startups quando comparado com Marketing e Administração.

```{r}
ggplot(data = dataset) +
    theme(legend.position="none")+
    geom_point(aes(x = PeD, y = Lucro, color = Estado)) +
    facet_grid(Estado ~ .) +
    labs(x = "P&D", y = "Lucro", title = "P&D X Lucro", subtitle =  "Análise de relação entre gasto com pesquisa & desenvolvimento e lucro")
```

```{r}
ggplot(data = dataset) +
    theme(legend.position="none")+
    geom_point(aes(x = PeD, y = Lucro, color = Estado)) +
    labs(x = "P&D", y = "Lucro", title = "P&D X Lucro", subtitle =  "Análise de relação entre gasto com pesquisa & desenvolvimento e lucro")
```

### Correlações

```{r}
numerical_columns = dataset[c("PeD", "Lucro", "Administracao", "Marketing")]
corrplot(cor(numerical_columns), method="color",  
         order="hclust", 
         addCoef.col = "black", 
         tl.col="black", tl.srt=45, 
         sig.level = 0.01, insig = "blank"
         )
```

### Comparação de estados

```{r}
ggplot(data = dataset) +
    geom_quasirandom(aes(x = Estado, y = Lucro, color = Estado, alpha = 0.3))+
    geom_boxplot(aes(x = Estado, y = Lucro, color = Estado, alpha = 0.3))+
    labs(x = "", y = "Lucro", title = "Lucros por estados")
```

## Pré-processamento dos dados

Antes de analisar os modelos que se adequam à problemática proposta, é necessário adaptar as variáveis que não são do tipo númerico, pois sem isto, elas não podem ser consideradas como parâmetros dos modelos de uma regressão linear.

A variável adaptada é a Estado, que pode assumir três valores categóricos: 'New York', 'California' e 'Florida'. Desse modo, ela foi transformada para receber respectivamente os valores 1, 2 e 3, possibilitando sua inclusão na construção do modelos.

```{r}
dataset$Estado = factor(dataset$Estado,
                       levels = c('New York', 'California', 'Florida'),
                       labels = c(1, 2, 3))

dataset$Estado <- as.numeric(levels(dataset$Estado)[dataset$Estado])
```

É necessário também dividir o conjunto de dados em dois conjuntos: de treinamento e de teste. O conjunto de dados de treinamento é utilizado para construir e treinar o modelo, já o de testes é utilizado para verificar o quão acertivo é são os modelos construídos.
80% dos dados foram utilizados para o conjunto de treinamento e 20% para o conjunto de teste.

```{r}
set.seed(100)
split = sample.split(dataset$Lucro, SplitRatio = 0.8)

training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
```

## Criando o Modelo de Regressão

### Encontrando o melhor modelo

A fim de encontrar o melhor modelo cujas variáveis impactam na inferência do Lucro, é utilizada a técnica **Backward Elimination**. Esta técnica é aplicada através dos seguintes passos:

1) Define-se o nível de significância;
2) Ajusta-se o modelo com todas as variáveis independentes possíveis;
3) Considera-se a variável com maior valor-p;
4) Se o valor p é maior que o nível de significância, remove-se a variável; 
5) Ajusta-se novamente o modelo, agora sem a variável removida.

OBS: No passo 4, visto que o valor-p > nível de significância, aceita-se a hipótese Ho e pode-se afirmar que o valor estimado para a variável é estatisticamente igual a zero, logo, ela não influencia consideravelmente e pode ser descartada do modelo.

#### Nível de Significância

O nível de significância adotado foi de 5%.

#### Modelo 1

Neste primeiro modelo consideramos todas as variáveis independentes: **Administracao**, **PeD**, **Marketing**, e **Estado**.

```{r}
regressor = lm(formula = Lucro ~ .,
               data = training_set)
summary(regressor)
```

A análise do modelo mostra que a variável com o maior valor-p acima do nível de significância é a **Administracao**, logo a mesma deve ser removida.


#### Modelo 2

Neste modelo considera-se as variáveis: **PeD**, **Marketing**, e **Estado**.

```{r}
regressor = lm(formula = Lucro ~ Marketing + PeD + Estado,
               data = training_set)
summary(regressor)
```

Através da análise é possível notar que a variável **Estado** possui o maior valor-p acima do nível de significância, assim ela deve ser desconsiderada do modelo.


#### Modelo 3

Neste modelo considera-se as variáveis: **PeD** e **Marketing**.

```{r}
regressor = lm(formula = Lucro ~ Marketing + PeD,
               data = training_set)
summary(regressor)
```

Analisando o modelo notamos que variável **Marketing** possui o maior valor-p acima do nível de significância, então ela deve ser removida do modelo.


#### Modelo 4

Neste modelo apenas a variável **PeD** é considerada.

```{r}
regressor = lm(formula = Lucro ~ PeD,
               data = training_set)
summary(regressor)
```

A análise do modelo mostra que a variável **PeD** apresenta um valor-p menor que o nível de significância definido (0.05), dessa forma ela deve pertencer ao modelo.
Assim finaliza-se o algoritmo **Backward Elimination**, e podemos afirmar que o modelo mais adequado é este último, composto apenas pela variável independente PeD.

### Conclusão

Foram construídos quatro modelos de regressão linear, no entanto, foi obtido apenas um para cujas variáveis independentes o valor-p é abaixo do nível de significância definido, ou seja, apenas um único modelo satisfatório. Desse modo, não foi necessário conduzir análises quanto ao R² e o R² Ajustado dos modelos, pois são métricas utilizadas para selecionar um modelo dentre vários válidos.

Além disso, o estudo inicialmente tinha como objetivo encontrar um modelo de regressão linear múltipla, que fosse capaz de inferir o lucro de startups a partir de algumas variáveis. No entanto, chegou-se a conclusão que o modelo mais adequado se caracteriza como uma regresssão linear simples, cuja variável independente é referente ao gasto com Pesquisa e Desenvolvimento (**PeD**).

Por fim, o modelo obteve um coeficiente de determinação (R²) de 0.9457, ou seja, podemos afirmar que 94,57% dos dados são explicados pelo modelo.

## Análise de Resíduos

Os resíduos representam as diferenças entre os valores do fenômeno que estamos observando, no nosso caso, são os valores que observamos no conjunto de dados e os valores estimados a partir do modelo. De modo formal, um resíduo pode ser obtido pela seguinte fórmula:

```
    ei = yi - yi'
```

onde:  
ei -> indica o iésimo erro  
yi -> indica o iésimo valor observado  
yi'-> indica o iésimo valor estimado  

A análise dos resíduos, consiste em validar se o modelo adotado, de fato, é adequado para o contexto do problema, baseado nas suposições feitas para os dados, são elas: 

 - **Linearidade**: Os dados devem ter uma relação linear.
 - **Normalidade**: Os resíduos devem seguir a distribuição normal, com média igual a 0 e variância constante.  
 - **Homogeneidade**: Os resíduos devem variar na mesma proporção. Desta forma, cada um contribui de forma igual para a soma dos quadrados.  
 - **Independência**: Um resíduo não deve influenciar o outro. Esta suposição garante que os dados foram coletados de modo aleatório no espaço amostral.

No gráfico abaixo, são representados os valores observados (representados pelos círculos ao longo da reta), os valores estimados (indicados pelos círculos coloridos maiores), e os resíduos (as linhas entre os valores estimados e os observados).

A partir dele, conseguimos visualizar a existência da relação linear entre as variáveis e como o modelo consegue explicar boa parte dos dados, conforme visto utilizando a estatística `R²` (que teve valor igual a 94%), demonstrando assim, que conseguimos explicar 94% dos dados.


```{r}
predicoes = predict(regressor)
residuos = residuals(regressor)

ggplot(training_set, aes(x = PeD, y = Lucro)) +
  geom_smooth(method = "lm", se = FALSE, color = "lightgrey") +     # regression line  
  geom_segment(aes(xend = PeD, yend = predicoes), alpha = .2) +     # draw line from point to line
  geom_point(aes(color = abs(residuos), size = abs(residuos))) +    # size of the points
  scale_color_continuous(low = "green", high = "red") +             # colour of the points mapped to residual size - green smaller, red larger
  guides(color = FALSE, size = FALSE) +                             # size legend removed
  geom_point(aes(y = predicoes), shape = 1) +
  theme_bw() 
```

### Teste da linearidade

O gráfico abaixo, mostra se os resíduos possuem padrões de relações não lineares.
Vemos que nossos resíduos não possuem padrões estranhos, pois mesmo embora possuam certa curvatura, os resíduos se distribuem ao longo da reta horizontal. O que nos dá um bom indicador que nossos dados possuem relação linear.


```{r}
plot(regressor, which=1, col=c("blue"))
```


### Teste de normalidade

O grafico do tipo `qxq`, é um tipo de gráfico de dispersão em que dado dois conjuntos de dados, é obtido os seus quantis ordenados. Em seguida são colocados os valores do primeiro contra os do segundo, de modo que, se os dois conjuntos de quantis forem da mesma distribuição, veremos os pontos formando uma linha que é praticamente uma reta.

Dessa forma, ele auxilia a verificar se um conjunto de dados veio de alguma distribuição teórica. Em nosso contexto, queremos verificar se os resíduos seguem distribuição normal, sendo assim, faremos uso dela.


```{r}
plot(regressor, which=2, col=c("blue"))
```

Do gráfico acima, conseguimos concluir que nosso modelo segue a distribuição normal, tendo em vista que os resíduos estão seguindo um bom alinhamento com a reta que o nosso modelo propõe.


```{r}
plot(density(residuos))
```

```{r}
shapiro.test(residuos)
```

Além da visualização do gráfico qxq, também decidimos usar o gráfico de densidade e o teste de shapiro. No gráfico da densidade, vemos que o formato é bem similar ao da distribuição normal, só não se comporta bem para valores baixos.

Por fim, analisamos o teste de shapiro-wilk. Para verificar se a nossa hipótese de que os resíduos seguem distribuição normal é verdadeira, analisamos o valor-p. Se ele for menor que o nosso nível de significância (nesse caso 0.05), rejeitamos a hipótese.

A partir do resultado acima, vemos que o valor-p é menor que o nível de significância e portanto deveríamos rejeitá-lo. Mas algo parece estranho, pelas análises visuais nossos resíduos parecem seguir uma distribuição normal, após algumas pesquisas, percebemos que o problema é porque temos dois valores muito abaixo das outras médias (nesse caso 0), que ocorreram quando as empresas não investiram em pesquisa e desenvolvimento. 

Pelo estudado, quando os valores são muito pequenos, o coeficiente não consegue identificar bem a presença de normalidade e por isso, obtivemos esse resultado. Sendo assim, podemos afirmar que de modo geral, nossos resíduos seguem distribuição normal.


### Teste da homogeneidade

Para verificar a homogeneidade dos resíduos, primeiro utilizamos o gráfico do tipo scale-location. Verificamos isso de duas formas:

1. A linha vermelha é aproximadamente horizontal. Então a magnitude média dos resíduos padronizados não está mudando muito em função dos valores ajustados.  
2. A propagação ao redor da linha vermelha não varia com os valores ajustados. Então a variabilidade de magnitude não varia muito em função dos valores ajustados.

Apesar de existir certa curvatura no nosso gráfico, de modo geral, ele se assemelha bastante ao formato linear. Além disso, a segunda condição também consegue ser satisfeita, pois não vemos uma forte concentração dos dados, em nenhum dos lados (inferior e superior). Logo, somos levados a acreditar que nossos resíduos possuem homogeinidade.


```{r}
plot(regressor, which=3, col=c("blue"))  # Scale-Location Plot
```


Usamos o teste de Breusch Pagan, para medir numericamente se nossa suposição está correta. Ele funciona como a estatística de teste usada anteriormente: analisando o valor-p, se ele for abaixo do nosso nível de significância, podemos rejeitar a nossa hipótese. Mas a partir da tabela abaixo vemos que o valor-p é maior, e portanto, podemos concluir que os resíduos são homogêneos.

```{r}
bptest(regressor)
```

### Teste da independência

Usamos a estatística Durbin-Watson para testar a presença de autocorrelação nos resíduos. A autocorrelação significa que um resíduo possui correlação com outro, ou seja, um resíduo afeta o valor do outro. Quando isso ocorre, a regressão de mínimos quadrados pode subestimar o erro padrão dos coeficientes. Os erros padrão subestimados podem fazer com que seus preditores pareçam significativos quando eles não são.

Para avaliar se os dados são de fato independentes, usamos a estratégia do valor-p novamente. A partir do resultado abaixo, vemos que o valor-p é menor que o nível de significância adotado, demonstrando assim, que os resíduos estão correlacionados, fazendo-se necessária uma adequação do modelo existente.

```{r}
durbinWatsonTest(regressor)
```

## Conclusões

Como descrito nas seções acima, a base de dados foi analisada descritivamente e foram aplicadas técnicas de seleção e validação, a fim de encontrar o modelo que melhor explicasse o lucro das startups.

O modelo foi o seguinte:

    Lucro = 47074,2420 + 0,8724 x PeD

### Explicado o modelo

Dado que não há gastos no setor de **PeD**, isto é, **PeD** é igual a zero, teremos um valor fixo para o **Lucro** em **47074,2420** unidades.
Além disso, dado cada acréscimo de uma unidade na **PeD**, teremos um acréscimo de **0,8724** unidades no **Lucro**.

### Caso de uso

Com o objetivo de exemplificar a utilização do modelo proposto, foram utilizados os seguintes valores para PeD:

1) 190150.89
2) 94712.60
3) 75642.33

```{r}
caso <- data.frame(
  PeD = c(190150.89, 94712.60, 75642.33)
)
```

Aplicando os valores no modelo de regressão, obtemos os seguintes valores para o Lucro, respectivamente:

```{r}
predict(regressor, newdata = caso)
```

