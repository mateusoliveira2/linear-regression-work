---
title: ""
author: "Fanny Batista Vieira, Marcus Vinícius de Farias Barbosa e Mateus de Lima Oliveira"
date: "13 de maio de 2019"
output:
  html_document:
    code_folding: "hide"
    toc: yes
    toc_depth: 5
    toc_float:
      collapsed: no
    df_print: paged
---

## Pergunta a ser respondida: Quais gastos interferem no lucro das startups ?

```{r}
library(tidyverse)
library(ggbeeswarm)
library(ggplot2)
library(corrplot)
library(caTools)
library(lmtest)
#library(car)

knitr::opts_chunk$set(tidy = FALSE, fig.width = 8, fig.height = 6, echo = TRUE)

options(scipen = 999)

dataset = read_csv(here::here("data/50_startups.csv"),
                 col_types = "dddcd")

names(dataset)[names(dataset) == 'ReD'] <- 'PeD'
names(dataset)[names(dataset) == 'Administration'] <- 'Administracao'
names(dataset)[names(dataset) == 'State'] <- 'Estado'
names(dataset)[names(dataset) == 'Profit'] <- 'Lucro'
```

## Motivação

Os dados utilizados possuem informações sobre 50 empresas. Temos cinco colunas que contêm informações sobre quanto essas empresas gastam em administração, pesquisa e desenvolvimento (P & D) e marketing, sua localização por estado e seu lucro no ano mais recente. Este conjunto de dados é anonimizado, o que significa que não sabemos os nomes dessas empresas ou qualquer outra informação de identificação.

Pensamos no cenário em que seriamos contratados para analisar essas informações e criar um modelo. Precisaríamos informar a pessoa que nos contratou em que tipo de empresa faz mais sentido investir no futuro, se é na que investe mais em administração por exemplo, ou em outro setor. O nosso empregador informou que quer tomar essa decisão com base no lucro do ano passado.

Para resolver esse problema, criaremos um modelo para avaliar quais departamentos de uma empresa é interessante investir, para maximizar seu lucro.

## Analise Descritiva

### Administração

Com base nas visualizações abaixo, podemos notar que há uma dispersão dos pontos de forma que não se pode afirmar que há uma correlação considerável em relação ao impacto de gastos com administração no lucro da startup. Nos três estados, existem pontos que estão no mesmo nivel de lucro mesmo conforme o investimento em administração cresce.


```{r}
ggplot(data = dataset) +
    theme(legend.position="none")+
    geom_point(aes(x = Administracao, y = Lucro, color = Estado)) +
    facet_grid(Estado ~ .) +
    labs(x = "Administração", y = "Lucro", title = "Administração X Lucro", subtitle =  "Analise de relação entre gasto com administração e o lucro")
```



### Marketing

No marketing a situação difere da administração. As startups tendem a ter um maior lucro de acordo com o investimento nesse setor nos três estados, pois ao passo que o valor investido cresce, os lucros também crescem.
Observa-se pontos que fogem dos da têndencia, logo, há uma correlação consideravel entre essas duas variáveis.



```{r}
ggplot(data = dataset) +
    theme(legend.position="none")+
    geom_point(aes(x = Marketing, y = Lucro, color = Estado))+
    facet_grid(Estado ~ .) +
    labs(x = "Marketing", y = "Lucro", title = "Marketing X Lucro", subtitle =  "Analise de relação entre gasto com marketing e lucro")
```




### Pesquisa e Desenvolvimento

Como esperado, há uma correlação quase linear em relação ao lucro e investimento em pesquisa e desenvolvimento. Não há pontos consideráveis que saiam da têndencia de crescimento linar que os pontos do gráfico seguem. 
Com isso, esse é o setor que gera um efeito positivo mais provável no lucro das startups quando comparado com Marketing e Administração.

```{r}
ggplot(data = dataset) +
    theme(legend.position="none")+
    geom_point(aes(x = PeD, y = Lucro, color = Estado)) +
    facet_grid(Estado ~ .) +
    labs(x = "P&D", y = "Lucro", title = "P&D X Lucro", subtitle =  "Análise de relação entre gasto com pesquisa & desenvolvimento e lucro")
```

```{r}
ggplot(data = dataset) +
    theme(legend.position="none")+
    geom_point(aes(x = PeD, y = Lucro, color = Estado)) +
    labs(x = "P&D", y = "Lucro", title = "P&D X Lucro", subtitle =  "Análise de relação entre gasto com pesquisa & desenvolvimento e lucro")
```


### Correlações

```{r}
numerical_columns = dataset[c("PeD", "Lucro", "Administracao", "Marketing")]
corrplot(cor(numerical_columns), method="color",  
         order="hclust", 
         addCoef.col = "black", 
         tl.col="black", tl.srt=45, 
         sig.level = 0.01, insig = "blank"
         )
```

### Comparação de estados

```{r}
ggplot(data = dataset) +
    geom_quasirandom(aes(x = Estado, y = Lucro, color = Estado, alpha = 0.3))+
    geom_boxplot(aes(x = Estado, y = Lucro, color = Estado, alpha = 0.3))+
    labs(x = "", y = "Lucro", title = "Lucros por estados")
```

## Pré-processamento dos dados

Antes de analisar os modelos que se adequam à problemática proposta, é necessário adaptar as variáveis que não são do tipo númerico, pois sem isto, elas não podem ser consideradas como parâmetros dos modelos de uma regressão linear.

A variável adaptada é a Estado, que pode assumir três valores categóricos: 'New York', 'California' e 'Florida'. Desse modo, ela foi transformada para receber respectivamente os valores 1, 2 e 3, possibilitando sua inclusão na construção do modelos.

```{r}
dataset$Estado = factor(dataset$Estado,
                       levels = c('New York', 'California', 'Florida'),
                       labels = c(1, 2, 3))
```

É necessário também dividir o conjunto de dados em dois conjuntos: de treinamento e de teste. O conjunto de dados de treinamento é utilizado para construir e treinar o modelo, já o de testes é utilizado para verificar o quão acertivo é são os modelos construídos.
80% dos dados foram utilizados para o conjunto de treinamento e 20% para o conjunto de teste.

```{r}
set.seed(100)
split = sample.split(dataset$Lucro, SplitRatio = 0.8)

training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
```

## Criando o Modelo de Regressão

### Encontrando o melhor modelo

A fim de encontrar o melhor modelo cujas variáveis impactam na inferência do Lucro, é utilizada a técnica **Backward Elimination**. Esta técnica é aplicada através dos seguintes passos:

1) Define-se o nível de significância;
2) Ajusta-se o modelo com todas as variáveis independentes possíveis;
3) Considera-se a variável com maior valor-p;
4) Se o valor p é maior que o nível de significância, remove-se a variável; 
5) Ajusta-se novamente o modelo, agora sem a variável removida.

#### Nível de Significância

O nível de significância adotado foi de 5%.

#### Modelo 1

Neste primeiro modelo consideramos todas as variáveis independentes: **Administracao**, **PeD**, **Marketing**, e **Estado**.

```{r}
regressor = lm(formula = Lucro ~ .,
               data = training_set)
summary(regressor)
```

A análise do modelo mostra que a variável com o maior valor-p acima do nível de significância é a **Administracao**, logo a mesma deve ser removida.


#### Modelo 2

Neste modelo considera-se as variáveis: **PeD**, **Marketing**, e **Estado**.

```{r}
regressor = lm(formula = Lucro ~ Marketing + PeD + Estado,
               data = training_set)
summary(regressor)
```

Através da análise é possivel notar que a variável Estado possui o maior valor-p acima do nível de significância, assim ela deve ser desconsiderada do modelo.


#### Modelo 3

Neste modelo considera-se as variáveis: **PeD** e **Marketing**.

```{r}
regressor = lm(formula = Lucro ~ Marketing + PeD,
               data = training_set)
summary(regressor)
```

Analisando o modelo notamos que variável **Marketing** possui o maior valor-p acima do nível de significância, então ela deve ser removida do modelo.


#### Modelo 4

Neste modelo apenas a variável **PeD** é considerada.

```{r}
regressor = lm(formula = Lucro ~ PeD,
               data = training_set)
summary(regressor)
```

A análise do modelo mostra que a variável **PeD** apresenta um valor-p menor que o nível de significância definido (0.05), dessa forma ela deve pertencer ao modelo.
Assim finaliza-se o algoritmo **Backward Elimination**, e podemos afirmar que o modelo mais adequado é este último, composto apenas pela variável independente PeD.

### Conclusão

Foram construídos quatro modelos de regressão linear, no entanto, foi obtido apenas um para cujas variáveis independentes o valor-p é abaixo do nível de significância definido, ou seja, apenas um único modelo válido. Desse modo, não foi necessário conduzir análises quanto ao R² e o R² Ajustado dos modelos, pois são métricas utilizadas para selecionar um modelo dentre vários válidos.
Além disso, o estudo inicialmente tinha como objetivo encontrar um modelo de regressão linear múltipla, que fosse capaz de inferir o lucro de startups a partir de algumas variáveis. No entanto, chegou-se a conclusão que o modelo mais adequado se caracteriza como uma regresssão linear simples, cuja variável independente é referente ao gasto com Pesquisa e Desenvolvimento.

## Análise de Resíduos

Os resíduos representam as diferenças entre os valores do fenômeno que estamos observando, no nosso caso, são os valores que observamos no dataset. E os valores estimados, a partir do nosso modelo. De modo formal, um resíduo pode ser obtido pela seguinte fórmula:

```
    ei = yi - yi'
```

onde:  
ei -> indica o iésimo erro  
yi -> indica o iésimo valor observado  
yi'-> indica o iésimo valor estimado  

A análise dos resíduos, consiste em validar se o modelo adotado, de fato, é adequado para o contexto do problema, baseado nas suposições feitas para os dados, são elas: 

 - **Linearidade**: Esperamos que os dados tenham uma relação linear.  
 - **Normalidade**: Os resíduos devem seguir a distribuição normal, com média igual a 0 e variância constante.  
 - **Homogeneidade**: Os resíduos devem variar na mesma proporção. Desta forma, cada um contribui de forma igual para a soma dos quadrados.  
 - **Independência**: Um resíduo não deve influenciar o outro, essa suposição, garante que os dados foram coletados de modo aleatório no espaço amostral.

No gráfico abaixo, vemos os valores observados, representados pelos círculos ao longo da reta, os valores estimados, indicados pelos círculos coloridos maiores, e os resíduos, que são as linhas entre os valores estimados e os observados.

A partir dele, conseguimos visualizar a existência da relação linear entre as variáveis, e como o modelo consegue explicar boa parte dos dados, conforme visto utilizando a estatística `R²`, que teve valor igual a 94%, demonstrando assim, que conseguimos explicar 94% dos dados.


```{r}
predicoes = predict(regressor)
residuos = residuals(regressor)

ggplot(training_set, aes(x = PeD, y = Lucro)) +
  geom_smooth(method = "lm", se = FALSE, color = "lightgrey") +     # regression line  
  geom_segment(aes(xend = PeD, yend = predicoes), alpha = .2) +     # draw line from point to line
  geom_point(aes(color = abs(residuos), size = abs(residuos))) +    # size of the points
  scale_color_continuous(low = "green", high = "red") +             # colour of the points mapped to residual size - green smaller, red larger
  guides(color = FALSE, size = FALSE) +                             # size legend removed
  geom_point(aes(y = predicoes), shape = 1) +
  theme_bw() 
```

### Teste da linearidade

O gráfico abaixo, mostra se os resíduos possuem padrões de relação não lineares.
Vemos que nossos resíduos não possuem padrões estranhos, embora possua certa curvatura, os resíduos se distribuem ao longo da reta horizontal. O que nos dá um bom indicador que nossos dados possuem relação linear.


```{r}
plot(regressor, which=1, col=c("blue"))
```


### Teste de normalidade

O grafico do tipo `qxq`, é um tipo de gráfico de dispersão em que dado dois conjuntos de dados, é obtido os seus quantis ordenados, e é colocado os valores do primeiro contra os do segundo, assim, se os dois conjuntos de quantis forem da mesma distribuição, veremos os pontos formando uma linha que é praticamente uma reta.

Dessa forma, ele auxilia a verificar se um conjunto de dados veio de alguma distribuição teórica, no nosso contexto, queremos verificar se os resíduos seguem distribuição normal, sendo assim, faremos uso dela.


```{r}
plot(regressor, which=2, col=c("blue"))
```

Do gráfico acima, conseguimos concluir que nosso modelo segue a distribuição normal, tendo em vista, que os resíduos estão seguindo um bom alinhamento com a reta que o nosso modelo propõe.


```{r}
plot(density(residuos))
```

```{r}
shapiro.test(residuos)
```

Além da visualização do gráfico qxq, também decidimos usar o gráfico de densidade e o teste shapiro. No gráfico da densidade, vemos que o formato, é bem similar ao da distribuição normal, só não se comporta bem para valores baixos.

Por fim, analisamos o teste de shapiro-wilk. Para verificar se a nossa hipótese de que os resíduos seguem distribuição normal é verdadeira, analisamos o valor p. Se ele for menor que o nosso nível de significância(nesse caso, 0.05), rejeitamos a hipotese.

A partir do resultado acima, vemos que o valor-p é menor que o nível de significância e portanto deveríamos rejeitá-lo. Mas algo parece estranho, pelas analises visuais nossos resíduos parecem seguir uma distribuição normal, após algumas pesquisas, percebemos que o problema é porque temos dois valores muito abaixo das outras médias(nesse caso, 0), que ocorreram quando as empresas não investiram em pesquisa e desenvolvimento. 

Pelo estudado, quando os valores são muito pequenos, o coeficiente não consegue identificar bem a presença de normalidade e por isso, obtivemos esse resultado. Sendo assim, podemos afirmar que de modo geral, nossos resíduos seguem distribuição normal.


### Teste da homogeinidade

Para verificar a homogeinidade, dos resíduos, primeiro, utilizamos o gráfico do tipo scale-location. Verificamos isso de duas formas:

1. A linha vermelha é aproximadamente horizontal. Então a magnitude média dos resíduos padronizados não está mudando muito em função dos valores ajustados.  
2. A propagação ao redor da linha vermelha não varia com os valores ajustados. Então a variabilidade de magnitude não varia muito em função dos valores ajustados.

Apesar de existir certa curvatura, no nosso gráfico, de modo geral, ele se assemelha bastante ao formato linear. Além disso, a segunda condição também consegue ser satisfeita, pois não vemos uma forte concentração dos dados, em nenhum dos lados(inferior e superior). Logo, somos levados a acreditar que nossos resíduos possuem homogeinidade.


```{r}
plot(regressor, which=3, col=c("blue"))  # Scale-Location Plot
```


Usamos o teste de Breusch Pagan, para medir numericamente se nossa suposição está correta. Ele funciona como a estatística de teste usada anteriormente, analisando o valor-p, se ele for abaixo do nosso nível de significância, podemos rejeitar a nossa hipótese. Mas da tabela abaixo, vemos que o valor-p é maior, e portanto podemos concluir que os resíduos são homogêneos.

```{r}
bptest(regressor)
```

### Teste da independência

Usamos a estatística Durbin-Watson para testar a presença de autocorrelação nos resíduos. A autocorrelação significa que os um resíduo está correlacionado ao outro, ou seja, um resíduo afeta o valor do outro. Quando isso ocorre, a regressão de mínimos quadrados pode subestimar o erro padrão dos coeficientes. Os erros padrão subestimados podem fazer com que seus preditores pareçam significativos quando eles não são.

Para avaliar se os nossos dados são de fato independentes, usamos a estratégia do p-valor novamente, do resultado abaixo, vemos que nosso valor-p é menor que o nível de significância adotado, demonstrando assim, que os nossos resíduos estão correlacionados, fazendo-se necessário uma adequação do modelo existente.

```{r}
#durbinWatsonTest(regressor)
```

## Conclusões 